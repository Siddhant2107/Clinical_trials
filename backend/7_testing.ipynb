{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"encoded_data_final_tf_idftarget1.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\",\"population\",\"NCT Number\"], inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv download karke raklo : 60 - 20 - 20, features in teeno similar hone chahahiye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data Split Done: X_train: (154545, 1314), X_val: (51515, 1314), X_test: (51516, 1314)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target column\n",
    "label_encoder = LabelEncoder()\n",
    "df['Study Status'] = label_encoder.fit_transform(df['Study Status'])  # Converts COMPLETED (1), NON COMPLETED (0)\n",
    "\n",
    "X = df.drop(columns=['Study Status'])\n",
    "y = df['Study Status']\n",
    "\n",
    "# Step 1: Split into 60% training and 40% temporary data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 2: Split temporary data into 20% validation and 20% test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f\"\\n✅ Data Split Done: X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets to CSV\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "val_df.to_csv(\"val_data.csv\", index=False)\n",
    "test_df.to_csv(\"test_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique columns: 1314\n",
      "Total columns in X_train: 1314\n",
      "\n",
      "Duplicate Columns:\n",
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Clean column names (to avoid errors with special characters)\n",
    "X_train.columns = X_train.columns.str.replace(r'[^a-zA-Z0-9_]', '_', regex=True)\n",
    "X_val.columns = X_val.columns.str.replace(r'[^a-zA-Z0-9_]', '_', regex=True)\n",
    "X_test.columns = X_test.columns.str.replace(r'[^a-zA-Z0-9_]', '_', regex=True)\n",
    "\n",
    "# Remove duplicate columns (if any)\n",
    "print(f\"Number of unique columns: {len(set(X_train.columns))}\")\n",
    "print(f\"Total columns in X_train: {X_train.shape[1]}\")\n",
    "print(\"\\nDuplicate Columns:\")\n",
    "print(X_train.columns[X_train.columns.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 132745, number of negative: 21800\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.587818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 235252\n",
      "[LightGBM] [Info] Number of data points in the train set: 154545, number of used features: 1308\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.858941 -> initscore=1.806520\n",
      "[LightGBM] [Info] Start training from score 1.806520\n",
      "\n",
      "🎯 Top 20 Important Features (LightGBM):\n",
      "                                        feature  importance\n",
      "1                                    Conditions         374\n",
      "5                                    Enrollment         369\n",
      "2                                 Interventions         363\n",
      "4                                        Phases         115\n",
      "270                                    duration         107\n",
      "278   Study_Design_Intervention_Model__PARALLEL          72\n",
      "225                       reason_90_100_percent          68\n",
      "219          reason_study_terminated_by_sponsor          55\n",
      "32                        country_United_States          50\n",
      "257                        reason_80_90_percent          49\n",
      "882                    TFIDF_criteria_criterion          46\n",
      "6                                   Funder_Type          45\n",
      "271                   Study_Design_Allocation__          43\n",
      "276  Study_Design_Intervention_Model__CROSSOVER          38\n",
      "274         Study_Design_Allocation__RANDOMIZED          36\n",
      "30                               country_France          31\n",
      "935                    TFIDF_criteria_inclusion          23\n",
      "0                                 Study_Results          23\n",
      "212                        period_overall_study          22\n",
      "210                        period_81_90_percent          22\n"
     ]
    }
   ],
   "source": [
    "# Apply LightGBM model\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.05, random_state=42)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Feature importance for LightGBM\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\n🎯 Top 20 Important Features (LightGBM):\")\n",
    "print(feature_importance_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔ Selected 234 features contributing to 95% importance.\n"
     ]
    }
   ],
   "source": [
    "# Select features contributing to 95% importance\n",
    "feature_importance_df[\"cumulative_importance\"] = (\n",
    "    feature_importance_df[\"importance\"].cumsum() / feature_importance_df[\"importance\"].sum()\n",
    ")\n",
    "selected_features = feature_importance_df[feature_importance_df[\"cumulative_importance\"] <= 0.95][\"feature\"].tolist()\n",
    "\n",
    "X_train_reduced = X_train[selected_features]\n",
    "X_val_reduced = X_val[selected_features]\n",
    "X_test_reduced = X_test[selected_features]\n",
    "\n",
    "print(f\"\\n✔ Selected {len(selected_features)} features contributing to 95% importance.\")\n",
    "                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2906290542.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_reduced.drop(columns=[col for col in features_to_drop if col in X_train_reduced.columns], inplace=True)\n",
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2906290542.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_reduced.drop(columns=[col for col in features_to_drop if col in X_val_reduced.columns], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now, drop unwanted features directly from X_train_reduced and X_val_reduced\n",
    "features_to_drop = [\n",
    "    \"TFIDF_secondaryoutcomes_due\",\"TFIDF_primaryoutcomes_higher\",\"TFIDF_secondaryoutcomes_life\",\"TFIDF_criteria_allowed\",\n",
    "    \"TFIDF_criteria_mass\",\"TFIDF_criteria_study\", \"TFIDF_criteria_within\", \"TFIDF_criteria_patient\",\n",
    "    \"TFIDF_summary_patient\", \"TFIDF_summary_treatment\", \"TFIDF_criteria_must\",\n",
    "    \"TFIDF_secondaryoutcomes_day\", \"TFIDF_secondaryoutcomes_time\",\n",
    "    \"TF_IDF_secondaryoutcomes_patient\", \"TF_IDF_criteria_week\",\n",
    "    \"TF_IDF_criteria_active\", \"TF_IDF_criteria_following\", \"TF_IDF_criteria_time\",\n",
    "    \"TFIDF_criteria_participate\", \"TFIDF_criteria_defined\", \"TFIDF_title_treatment\",\n",
    "    \"TF_IDF_criteria_may\", \"TFIDF_primaryoutcomes_scale\", \"TFIDF_primaryoutcomes_patient\",\n",
    "    \"TFIDF_secondaryoutcomes_study\", \"TFIDF_primaryoutcomes_number\",\n",
    "    \"TFIDF_primaryoutcomes_defined\", \"TFIDF_secondaryoutcomes_scale\",\n",
    "    \"TFIDF_secondaryoutcomes_event\", \"TF_IDF_criteria_enrollment\",\n",
    "    \"TFIDF_criteria_criterion\", \"TFIDF_criteria_inclusion\", \"TFIDF_criteria_known\",\n",
    "    \"TFIDF_criteria_prior\", \"TFIDF_criteria_authorized\", \"TFIDF_criteria_day\",\n",
    "    \"TFIDF_criteria_randomization\", \"TFIDF_criteria_problem\", \"TFIDF_criteria_failure\",\n",
    "    \"TFIDF_criteria_evidence\", \"TFIDF_criteria_concurrent\", \"TFIDF_criteria_risk\",\n",
    "    \"TFIDF_criteria_agent\", \"TFIDF_criteria_treatment\", \"TFIDF_criteria_measurable\",\n",
    "    \"TFIDF_criteria_equal\", \"TFIDF_criteria_including\", \"TFIDF_criteria_interval\",\n",
    "    \"TFIDF_criteria_subject\", \"TFIDF_criteria_status\", \"TFIDF_criteria_requiring\",\n",
    "    \"TFIDF_criteria_opinion\", \"TFIDF_criteria_basal\",\n",
    "    \"TFIDF_secondaryoutcomes_unknownmeasures\", \"TFIDF_secondaryoutcomes_length\",\n",
    "    \"TFIDF_secondaryoutcomes_endpoint\", \"TFIDF_secondaryoutcomes_proportion\",\n",
    "    \"TFIDF_secondaryoutcomes_hazard\", \"TFIDF_secondaryoutcomes_objective\",\n",
    "    \"TFIDF_secondaryoutcomes_response\", \"TFIDF_secondaryoutcomes_defined\",\n",
    "    \"TFIDF_primaryoutcomes_rate\", \"TFIDF_primaryoutcomes_year\",\n",
    "    \"TFIDF_primaryoutcomes_phase\", \"TFIDF_primaryoutcomes_progression\",\n",
    "    \"TFIDF_primaryoutcomes_safety\", \"TFIDF_primaryoutcomes_enrolled\",\n",
    "    \"TFIDF_primaryoutcomes_efficacy\", \"TFIDF_primaryoutcomes_primary\",\n",
    "    \"TFIDF_primaryoutcomes_clinical\", \"TFIDF_primaryoutcomes_combination\",\n",
    "    \"TFIDF_primaryoutcomes_cmax\", \"TFIDF_primaryoutcomes_cause\",\n",
    "    \"TFIDF_primaryoutcomes_area\", \"TFIDF_primaryoutcomes_curve\",\n",
    "    \"TFIDF_primaryoutcomes_objective\", \"TFIDF_primaryoutcomes_visual\",\n",
    "    \"TFIDF_primaryoutcomes_criterion\", \"TFIDF_primaryoutcomes_unknownprimarymeasures\",\n",
    "    \"TFIDF_primaryoutcomes_intervention\", \"TFIDF_primaryoutcomes_absorption\",\n",
    "    \"TFIDF_primaryoutcomes_improvement\", \"TFIDF_summary_standard\",\n",
    "    \"TFIDF_summary_intervention\", \"TFIDF_summary_multicenter\", \"TFIDF_summary_program\",\n",
    "    \"TFIDF_summary_aimed\", \"TFIDF_summary_safe\", \"TFIDF_summary_volunteer\",\n",
    "    \"TFIDF_summary_exercise\", \"TFIDF_summary_spread\", \"TFIDF_summary_may\",\n",
    "    \"TFIDF_summary_help\", \"TFIDF_summary_drug\", \"TFIDF_summary_cell\",\n",
    "    \"TFIDF_summary_stage\", \"TFIDF_summary_progression\", \"TFIDF_summary_determine\",\n",
    "    \"TFIDF_title_registry\", \"TFIDF_title_effect\", \"TFIDF_title_patient\",\n",
    "    \"TFIDF_title_solid\", \"TFIDF_title_intervention\", \"TFIDF_title_negative\",\n",
    "    \"TFIDF_title_healthy\", \"TFIDF_secondaryoutcomes_patient\", \"TFIDF_criteria_active\",\n",
    "    \"TFIDF_criteria_following\", \"TFIDF_criteria_may\", \"TFIDF_criteria_week\",\n",
    "    \"TFIDF_criteria_greater\", \"TFIDF_criteria_time\", \"TFIDF_criteria_defined\"\n",
    "]\n",
    "\n",
    "# Drop the selected features directly from the datasets\n",
    "X_train_reduced.drop(columns=[col for col in features_to_drop if col in X_train_reduced.columns], inplace=True)\n",
    "X_val_reduced.drop(columns=[col for col in features_to_drop if col in X_val_reduced.columns], inplace=True)\n",
    "\n",
    "# Now, X_train_reduced and X_val_reduced will have the dropped features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2498038521.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_reduced.drop(columns=[col for col in features_to_drop if col in X_test_reduced.columns], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_test_reduced.drop(columns=[col for col in features_to_drop if col in X_test_reduced.columns], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m val_df_reduced \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_val_reduced, y_val], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m test_df_reduced \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([X_test_reduced, y_test], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrain_df_reduced\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_data_reduced.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m val_df_reduced\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_data_reduced.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m test_df_reduced\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_data_reduced.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3718\u001b[0m )\n\u001b[1;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1188\u001b[0m )\n\u001b[1;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    259\u001b[0m     )\n\u001b[1;32m--> 261\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[1;34m(self, start_i, end_i)\u001b[0m\n\u001b[0;32m    312\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[0;32m    314\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[1;32m--> 315\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\pandas\\_libs\\writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Save the reduced train, validation, and test datasets\n",
    "train_df_reduced = pd.concat([X_train_reduced, y_train], axis=1)\n",
    "val_df_reduced = pd.concat([X_val_reduced, y_val], axis=1)\n",
    "test_df_reduced = pd.concat([X_test_reduced, y_test], axis=1)\n",
    "\n",
    "train_df_reduced.to_csv(\"train_data_reduced.csv\", index=False)\n",
    "val_df_reduced.to_csv(\"val_data_reduced.csv\", index=False)\n",
    "test_df_reduced.to_csv(\"test_data_reduced.csv\", index=False)\n",
    "\n",
    "print(\"\\n💾 Train, validation, and test datasets (reduced) saved as CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Checking Feature Distributions:\n",
      "\n",
      "📊 Top 20 Feature Distribution Differences (Train vs Val & Test):\n",
      "                                                    Train Mean  \\\n",
      "Phases                                                5.388295   \n",
      "Funder_Type                                           5.065243   \n",
      "country_Germany                                       0.057427   \n",
      "country_France                                        0.071138   \n",
      "country_countries_with_low_cumsum_value               0.161694   \n",
      "organ_system_Gastrointestinal_disorders               0.107451   \n",
      "Study_Design_Intervention_Model__CROSSOVER            0.076321   \n",
      "Study_Type                                            0.205591   \n",
      "Study_Design_Intervention_Model__PARALLEL             0.457802   \n",
      "country_United_States                                 0.397632   \n",
      "event_type_other                                      0.137216   \n",
      "period_overall_study                                  0.098282   \n",
      "healthy_volunteers                                    0.261768   \n",
      "duration                                              3.022985   \n",
      "Enrollment                                            3.990145   \n",
      "assessment_type_SYSTEMATIC_ASSESSMENT                 0.102553   \n",
      "Study_Design_Masking__QUADRUPLE__PARTICIPANT__C...    0.078333   \n",
      "Study_Design_Allocation__NA                           0.165660   \n",
      "Study_Results                                         0.200511   \n",
      "sampling_method                                       1.667210   \n",
      "\n",
      "                                                    Validation Mean  \\\n",
      "Phases                                                     5.403184   \n",
      "Funder_Type                                                5.076677   \n",
      "country_Germany                                            0.054004   \n",
      "country_France                                             0.067844   \n",
      "country_countries_with_low_cumsum_value                    0.158517   \n",
      "organ_system_Gastrointestinal_disorders                    0.104533   \n",
      "Study_Design_Intervention_Model__CROSSOVER                 0.079064   \n",
      "Study_Type                                                 0.208211   \n",
      "Study_Design_Intervention_Model__PARALLEL                  0.455285   \n",
      "country_United_States                                      0.399884   \n",
      "event_type_other                                           0.134990   \n",
      "period_overall_study                                       0.096147   \n",
      "healthy_volunteers                                         0.263768   \n",
      "duration                                                   3.024981   \n",
      "Enrollment                                                 3.988264   \n",
      "assessment_type_SYSTEMATIC_ASSESSMENT                      0.100689   \n",
      "Study_Design_Masking__QUADRUPLE__PARTICIPANT__C...         0.076618   \n",
      "Study_Design_Allocation__NA                                0.164049   \n",
      "Study_Results                                              0.198971   \n",
      "sampling_method                                            1.665767   \n",
      "\n",
      "                                                    Test Mean  Train-Val Diff  \\\n",
      "Phases                                               5.385026        0.014889   \n",
      "Funder_Type                                          5.072172        0.011434   \n",
      "country_Germany                                      0.056002        0.003423   \n",
      "country_France                                       0.071822        0.003294   \n",
      "country_countries_with_low_cumsum_value              0.159251        0.003177   \n",
      "organ_system_Gastrointestinal_disorders              0.107675        0.002918   \n",
      "Study_Design_Intervention_Model__CROSSOVER           0.075918        0.002744   \n",
      "Study_Type                                           0.205878        0.002621   \n",
      "Study_Design_Intervention_Model__PARALLEL            0.458595        0.002517   \n",
      "country_United_States                                0.398536        0.002252   \n",
      "event_type_other                                     0.137879        0.002226   \n",
      "period_overall_study                                 0.097426        0.002135   \n",
      "healthy_volunteers                                   0.263433        0.001999   \n",
      "duration                                             3.033914        0.001996   \n",
      "Enrollment                                           3.994982        0.001881   \n",
      "assessment_type_SYSTEMATIC_ASSESSMENT                0.103677        0.001864   \n",
      "Study_Design_Masking__QUADRUPLE__PARTICIPANT__C...   0.078616        0.001715   \n",
      "Study_Design_Allocation__NA                          0.166977        0.001611   \n",
      "Study_Results                                        0.200753        0.001540   \n",
      "sampling_method                                      1.667560        0.001443   \n",
      "\n",
      "                                                    Train-Test Diff  \n",
      "Phases                                                     0.003269  \n",
      "Funder_Type                                                0.006929  \n",
      "country_Germany                                            0.001425  \n",
      "country_France                                             0.000684  \n",
      "country_countries_with_low_cumsum_value                    0.002443  \n",
      "organ_system_Gastrointestinal_disorders                    0.000224  \n",
      "Study_Design_Intervention_Model__CROSSOVER                 0.000403  \n",
      "Study_Type                                                 0.000287  \n",
      "Study_Design_Intervention_Model__PARALLEL                  0.000793  \n",
      "country_United_States                                      0.000905  \n",
      "event_type_other                                           0.000664  \n",
      "period_overall_study                                       0.000856  \n",
      "healthy_volunteers                                         0.001664  \n",
      "duration                                                   0.010930  \n",
      "Enrollment                                                 0.004838  \n",
      "assessment_type_SYSTEMATIC_ASSESSMENT                      0.001124  \n",
      "Study_Design_Masking__QUADRUPLE__PARTICIPANT__C...         0.000283  \n",
      "Study_Design_Allocation__NA                                0.001317  \n",
      "Study_Results                                              0.000242  \n",
      "sampling_method                                            0.000349  \n"
     ]
    }
   ],
   "source": [
    "# ✅ Check feature distribution across Train, Val, and Test sets\n",
    "print(\"\\n🔍 Checking Feature Distributions:\")\n",
    "\n",
    "train_mean = X_train_reduced.mean()\n",
    "val_mean = X_val_reduced.mean()\n",
    "test_mean = X_test_reduced.mean()\n",
    "\n",
    "distribution_df = pd.DataFrame({\n",
    "    \"Train Mean\": train_mean,\n",
    "    \"Validation Mean\": val_mean,\n",
    "    \"Test Mean\": test_mean\n",
    "})\n",
    "\n",
    "# Show top 20 features with distribution difference\n",
    "distribution_df[\"Train-Val Diff\"] = abs(distribution_df[\"Train Mean\"] - distribution_df[\"Validation Mean\"])\n",
    "distribution_df[\"Train-Test Diff\"] = abs(distribution_df[\"Train Mean\"] - distribution_df[\"Test Mean\"])\n",
    "\n",
    "print(\"\\n📊 Top 20 Feature Distribution Differences (Train vs Val & Test):\")\n",
    "print(distribution_df.sort_values(by=[\"Train-Val Diff\", \"Train-Test Diff\"], ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2242360006.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_reduced.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2242360006.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_reduced.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2242360006.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_reduced.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2242360006.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_reduced.fillna(X_train_reduced.mean(), inplace=True)\n",
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2242360006.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_val_reduced.fillna(X_val_reduced.mean(), inplace=True)\n",
      "C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_11744\\2242360006.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_reduced.fillna(X_test_reduced.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Replaced Inf values and handled missing data.\n"
     ]
    }
   ],
   "source": [
    "# Handle missing data (replace Inf and NaN values)\n",
    "X_train_reduced.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_val_reduced.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test_reduced.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "X_train_reduced.fillna(X_train_reduced.mean(), inplace=True)\n",
    "X_val_reduced.fillna(X_val_reduced.mean(), inplace=True)\n",
    "X_test_reduced.fillna(X_test_reduced.mean(), inplace=True)\n",
    "\n",
    "print(\"✔ Replaced Inf values and handled missing data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Applied Standard Scaling to Features.\n"
     ]
    }
   ],
   "source": [
    "# Apply Standard Scaling to features\n",
    "scaler = StandardScaler()\n",
    "X_train_reduced = pd.DataFrame(scaler.fit_transform(X_train_reduced), columns=X_train_reduced.columns)\n",
    "X_val_reduced = pd.DataFrame(scaler.transform(X_val_reduced), columns=X_val_reduced.columns)\n",
    "X_test_reduced = pd.DataFrame(scaler.transform(X_test_reduced), columns=X_test_reduced.columns)\n",
    "\n",
    "print(\"✔ Applied Standard Scaling to Features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Saved the scaler as 'scaler.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# Save the fitted scaler to a pickle file\n",
    "import pickle\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print(\"✔ Saved the scaler as 'scaler.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔ Computed Class Weights: {0: 3.5446100917431194, 1: 0.5821123206147124}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "print(\"\\n✔ Computed Class Weights:\", class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Logistic Regression Model Performance (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.83      0.69      7267\n",
      "           1       0.97      0.90      0.94     44248\n",
      "\n",
      "    accuracy                           0.89     51515\n",
      "   macro avg       0.78      0.87      0.81     51515\n",
      "weighted avg       0.92      0.89      0.90     51515\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9376\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    solver='liblinear',\n",
    "    class_weight=class_weight_dict,\n",
    "    random_state=42\n",
    ")\n",
    "log_reg.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict on validation and test sets\n",
    "y_pred_val = log_reg.predict(X_val_reduced)\n",
    "y_pred_test = log_reg.predict(X_test_reduced)\n",
    "\n",
    "# Evaluate model performance on validation set\n",
    "y_pred_proba_val = log_reg.predict_proba(X_val_reduced)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "print(\"\\n🎯 Logistic Regression Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Logistic Regression Model Performance (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69      7267\n",
      "           1       0.97      0.90      0.94     44249\n",
      "\n",
      "    accuracy                           0.89     51516\n",
      "   macro avg       0.78      0.87      0.81     51516\n",
      "weighted avg       0.92      0.89      0.90     51516\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9392\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance on test set\n",
    "y_pred_proba_test = log_reg.predict_proba(X_test_reduced)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n🎯 Logistic Regression Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 XGBoost Model Performance (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      7267\n",
      "           1       0.97      0.94      0.96     44248\n",
      "\n",
      "    accuracy                           0.92     51515\n",
      "   macro avg       0.83      0.88      0.85     51515\n",
      "weighted avg       0.93      0.92      0.93     51515\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9587\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight= y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict on validation and test sets\n",
    "y_pred_val = xgb_model.predict(X_val_reduced)\n",
    "y_pred_test = xgb_model.predict(X_test_reduced)\n",
    "\n",
    "# Evaluate model performance on validation set\n",
    "y_pred_proba_val = xgb_model.predict_proba(X_val_reduced)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 XGBoost Model Performance (Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85     21800\n",
      "           1       0.99      0.96      0.97    132745\n",
      "\n",
      "    accuracy                           0.95    154545\n",
      "   macro avg       0.89      0.94      0.91    154545\n",
      "weighted avg       0.96      0.95      0.95    154545\n",
      "\n",
      "🔹 AUC-ROC (Training Set): 0.9877\n",
      "\n",
      "🎯 XGBoost Model Performance (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      7267\n",
      "           1       0.97      0.94      0.96     44248\n",
      "\n",
      "    accuracy                           0.92     51515\n",
      "   macro avg       0.83      0.88      0.85     51515\n",
      "weighted avg       0.93      0.92      0.93     51515\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9587\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Predict on training set\n",
    "y_pred_train = xgb_model.predict(X_train_reduced)\n",
    "y_pred_proba_train = xgb_model.predict_proba(X_train_reduced)[:, 1]\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_val = xgb_model.predict(X_val_reduced)\n",
    "y_pred_proba_val = xgb_model.predict_proba(X_val_reduced)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "# Print classification report and AUC-ROC for training set\n",
    "print(\"\\n🎯 XGBoost Model Performance (Training Set):\")\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print(f\"🔹 AUC-ROC (Training Set): {roc_auc_train:.4f}\")\n",
    "\n",
    "# Print classification report and AUC-ROC for validation set\n",
    "print(\"\\n🎯 XGBoost Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 XGBoost Model Performance (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      7267\n",
      "           1       0.97      0.94      0.96     44249\n",
      "\n",
      "    accuracy                           0.92     51516\n",
      "   macro avg       0.83      0.87      0.85     51516\n",
      "weighted avg       0.93      0.92      0.93     51516\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9577\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance on test set\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test_reduced)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 XGBoost model saved to 'xgb_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained XGBoost model to a pickle file\n",
    "with open('xgb_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(xgb_model, model_file)\n",
    "\n",
    "print(\"🎯 XGBoost model saved to 'xgb_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Replaced Inf values and handled missing data.\n",
      "✔ Applied Standard Scaling to Features.\n",
      "🎯 Accuracy on the new data: 0.9244\n",
      "\n",
      "🎯 Classification Report on the new data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.81      0.75      7267\n",
      "           1       0.97      0.94      0.96     44249\n",
      "\n",
      "    accuracy                           0.92     51516\n",
      "   macro avg       0.83      0.87      0.85     51516\n",
      "weighted avg       0.93      0.92      0.93     51516\n",
      "\n",
      "🔹 AUC-ROC on the new data: 0.9577\n",
      "   Predicted  Probability\n",
      "0          0     0.220974\n",
      "1          1     0.997394\n",
      "2          1     0.999803\n",
      "3          1     0.995838\n",
      "4          0     0.013547\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# Load the X_test data (already preprocessed and reduced)\n",
    "x_test_val_df = pd.read_csv('test_data_reduced.csv')  # Replace with your actual CSV file path\n",
    "\n",
    "# Extract true labels\n",
    "y_true_new_data = x_test_val_df['Study Status']  # Replace with the correct column name if needed\n",
    "X_test_reduced = x_test_val_df.drop(columns=['Study Status'])  # Drop target column from features\n",
    "\n",
    "# Handle missing data (replace Inf and NaN values)\n",
    "X_test_reduced.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test_reduced.fillna(X_test_reduced.mean(), inplace=True)\n",
    "\n",
    "print(\"✔ Replaced Inf values and handled missing data.\")\n",
    "\n",
    "# Load the trained StandardScaler used during training\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Apply the same Standard Scaling transformation\n",
    "X_test_reduced = pd.DataFrame(scaler.transform(X_test_reduced), columns=X_test_reduced.columns)\n",
    "\n",
    "print(\"✔ Applied Standard Scaling to Features.\")\n",
    "\n",
    "# Load the trained XGBoost model from pickle file\n",
    "with open('xgb_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "\n",
    "# Predict on the new data\n",
    "y_pred_new_data = xgb_model.predict(X_test_reduced)  # Predict the class labels\n",
    "y_pred_proba_new_data = xgb_model.predict_proba(X_test_reduced)[:, 1]  # Predict probabilities for AUC\n",
    "\n",
    "# Evaluate model performance on the new data\n",
    "accuracy = accuracy_score(y_true_new_data, y_pred_new_data)\n",
    "roc_auc_new_data = roc_auc_score(y_true_new_data, y_pred_proba_new_data)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"🎯 Accuracy on the new data: {accuracy:.4f}\")\n",
    "print(\"\\n🎯 Classification Report on the new data:\")\n",
    "print(classification_report(y_true_new_data, y_pred_new_data))\n",
    "print(f\"🔹 AUC-ROC on the new data: {roc_auc_new_data:.4f}\")\n",
    "\n",
    "# Optionally, save predictions to a CSV file\n",
    "predictions_df = pd.DataFrame({'Predicted': y_pred_new_data, 'Probability': y_pred_proba_new_data})\n",
    "predictions_df.to_csv('predictions_on_new_data.csv', index=False)\n",
    "\n",
    "# Print first few predictions\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 XGBoost Model Performance (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.82      0.75      3634\n",
      "           1       0.97      0.94      0.95     22124\n",
      "\n",
      "    accuracy                           0.92     25758\n",
      "   macro avg       0.83      0.88      0.85     25758\n",
      "weighted avg       0.93      0.92      0.93     25758\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9598\n",
      "\n",
      "📝 Sample Inputs and Predictions:\n",
      "\n",
      "Example 1:\n",
      "Input Features: [ 0.25814246 -0.53715217 -0.0111203   0.73342263  0.45012499  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403   4.06465962 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.6344\n",
      "\n",
      "Example 2:\n",
      "Input Features: [ 0.93850949  0.18979278  0.69337499  0.73342263  0.27627822  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9997\n",
      "\n",
      "Example 3:\n",
      "Input Features: [-0.35994409  0.14940824  0.22371146  0.27805     0.90678191  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166  9.38113711 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475  8.72487025 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218  2.87013787 -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615   3.24674018 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.6587\n",
      "\n",
      "Example 4:\n",
      "Input Features: [ 0.20982841 -0.48355357 -0.0111203   0.73342263  0.51215827 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      "  0.42161182 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.6587\n",
      "\n",
      "Example 5:\n",
      "Input Features: [ 0.93850949 -0.34379884  0.69337499  0.73342263 -3.09613986  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211  5.37881197 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403   1.63336855 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702  6.18631387 -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9999\n",
      "\n",
      "Example 6:\n",
      "Input Features: [ 0.93850949 -0.17584439 -2.0920264   0.27805     1.00430669  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      "  3.58490343 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402  2.94312691 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909  2.35949951 -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9589\n",
      "\n",
      "Example 7:\n",
      "Input Features: [ 0.75911788  0.28156193 -0.62991916  0.27805    -0.1970947  -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445   1.99902993 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786  0.84619965 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498  2.49277049\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294  7.62079635\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.8125\n",
      "\n",
      "Example 8:\n",
      "Input Features: [ 0.93850949  1.19574919 -0.0111203   0.73342263  0.15575841  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9980\n",
      "\n",
      "Example 9:\n",
      "Input Features: [ 0.93850949  1.31066672  0.24279096  0.73342263 -2.38688689 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      "  3.58490343 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786  1.1334228  -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9981\n",
      "\n",
      "Example 10:\n",
      "Input Features: [ 0.38578939 -0.48355357 -0.0111203   0.73342263  0.19752894  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837  4.82266336 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.7013\n",
      "\n",
      "Example 11:\n",
      "Input Features: [ 0.31043728 -0.17584439  0.69337499  0.73342263 -0.84786114 -0.91735919\n",
      "  5.70598689 -0.02226977  5.62345235  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156  1.99902993 -0.0834951   3.01364328\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      "  2.2401525  -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498  2.49277049\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9968\n",
      "\n",
      "Example 12:\n",
      "Input Features: [ 0.65447277 -0.01383735  0.69337499 -1.08806787  0.15575841 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532 -1.44128935 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      "  2.2401525  -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9989\n",
      "\n",
      "Example 13:\n",
      "Input Features: [ 0.03825224 -0.17584439 -0.11767626 -0.17732262  0.38408687  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498  3.4362055  -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909  1.90690517 -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.5650\n",
      "\n",
      "Example 14:\n",
      "Input Features: [ 8.62597046e-03  1.31066672e+00 -1.11203001e-02  7.33422628e-01\n",
      "  1.38770642e+00  1.09008556e+00 -1.64760418e-01 -2.22697745e-02\n",
      " -1.67466192e-01 -8.10455318e-01  6.50174738e-01 -1.25855172e-01\n",
      " -2.71739278e-01 -2.88262883e-01  9.48144495e-01 -5.00242636e-01\n",
      " -8.34950952e-02 -3.25396796e-01 -5.41587643e-01 -1.75948368e-01\n",
      " -1.93288546e-01 -1.89125674e-01 -1.53190246e-01  5.83012762e-01\n",
      " -8.70721080e-02 -1.24631740e-01 -4.91226529e-02 -2.41297856e-01\n",
      " -2.39196944e-01 -1.07664568e-01 -4.46398180e-01 -1.16312625e-01\n",
      " -2.50435628e-01 -1.08984017e-01 -1.15969555e-01 -5.25515152e-01\n",
      " -8.10616197e-02 -1.97895707e-01 -1.24957535e-01 -4.52116592e-02\n",
      " -1.48376695e-01 -9.80068262e-02 -1.24515482e-01 -3.42919378e-01\n",
      " -6.16047393e-02 -1.61640004e-01 -1.17144979e-01 -3.95346591e-01\n",
      " -1.48667026e-01 -1.74710873e-01 -7.52347516e-02 -1.29875868e-01\n",
      " -1.55419013e-01 -1.13649505e-01  1.30665463e-02 -3.34284982e-01\n",
      " -2.91018683e-01 -7.99468099e-02 -6.91252129e-02 -1.35070319e-01\n",
      " -1.33157883e-01 -1.27238276e-01 -1.36899357e-01 -1.20391452e-01\n",
      " -1.08112860e-01 -5.47634295e-02  1.13399718e+01 -2.16740297e-01\n",
      " -2.50905845e-01 -2.20503762e-01 -5.06071757e-02 -6.63313936e-02\n",
      " -3.83614985e-02 -2.30453648e-01 -4.47470222e-02 -1.17435001e-01\n",
      " -1.94492694e-01 -1.27095264e-01 -1.23123439e-01 -1.58196677e-01\n",
      " -2.04817658e-01 -1.20316971e-01 -5.06565849e-01 -4.16672467e-02\n",
      " -2.70377639e-01 -1.07263182e-01 -2.02598945e-01 -6.41358754e-02\n",
      " -1.08354167e-01 -2.69022925e-01 -4.53442669e-02 -2.92399086e-01\n",
      " -3.26805803e-01 -4.68597724e-01 -5.22429414e-02 -1.69215441e-01\n",
      " -9.21659987e-02 -1.21239444e-01 -1.78704574e-01 -1.60674018e-01\n",
      " -7.09836149e-02 -1.70329645e-01 -2.18631058e-01 -1.55365735e-01\n",
      " -1.23572686e-01 -1.65997670e-01 -8.53966115e-02 -4.79526982e-02]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.8418\n",
      "\n",
      "Example 15:\n",
      "Input Features: [ 0.57972627 -0.3873404  -0.0111203   0.73342263 -1.67763392 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928  3.46905571  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164     2.48661197 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9815\n",
      "\n",
      "Example 16:\n",
      "Input Features: [-0.66739043 -0.84796353  0.69337499  0.73342263  0.75245454 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427  2.15111264 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9803\n",
      "\n",
      "Example 17:\n",
      "Input Features: [ 0.25937672  0.91452374  0.69337499  0.73342263  0.15575841 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9979\n",
      "\n",
      "Example 18:\n",
      "Input Features: [ 0.06076827  0.21861502  0.69337499 -1.99881312  0.92704466 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294 -1.44128935 -0.12585517\n",
      "  3.58490343 -0.28826288 -1.05469156  1.99902993 -0.0834951   3.01364328\n",
      " -0.54158764 -0.17594837 -0.19328855  0.09267447 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265  4.01388711 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162  0.720715   -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548  2.86403201 -0.06160474 -0.16164    -0.11714498  2.49277049\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655  2.93588039 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      "  2.9769142  -0.10726318 -0.20259895 -0.06413588 -0.10835417  3.61950569\n",
      " -0.04534427  2.86493057  3.16376532  2.37591543 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      "  0.21306617 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9869\n",
      "\n",
      "Example 19:\n",
      "Input Features: [ 0.23659676  0.10653698 -0.0111203   0.73342263  0.94691394  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445   1.99902993 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548  2.86403201 -0.06160474 -0.16164    -0.11714498  2.49277049\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498  3.4362055  -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058   0.69481604 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      "  4.42197875 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.8507\n",
      "\n",
      "Example 20:\n",
      "Input Features: [ 0.75911788 -0.65857852  0.69337499 -1.99881312 -0.74005249 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532 -1.44128935 -0.12585517\n",
      " -0.27173928  3.46905571  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837  5.12997179 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703  5.75457294 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403   6.85457258 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294  1.18506979\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9989\n",
      "\n",
      "Example 21:\n",
      "Input Features: [ 0.41037189  0.69662752 -0.58423695 -0.17732262 -0.55349456  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218  1.68951078 -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058   0.36044528 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      "  2.7951694  -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.8664\n",
      "\n",
      "Example 22:\n",
      "Input Features: [ 0.59766543  1.17936165 -0.0111203   0.73342263  0.88610978  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265  4.01388711 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.8791\n",
      "\n",
      "Example 23:\n",
      "Input Features: [ 0.17662276  0.08406928  0.34112734 -1.08806787  0.15575841  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294 -1.44128935 -0.12585517\n",
      "  3.58490343 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -2.61142739 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263  3.87497532 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      "  7.50988207 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.5014\n",
      "\n",
      "Example 24:\n",
      "Input Features: [-0.05908289  0.18979278 -0.0111203   0.73342263  0.06672526  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403   2.35645623 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.8708\n",
      "\n",
      "Example 25:\n",
      "Input Features: [ 0.55368555  0.41424615 -0.0111203   0.27805    -0.39576207 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928  3.46905571  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9186\n",
      "\n",
      "Example 26:\n",
      "Input Features: [ 0.93850949 -0.19262684  0.69337499  0.73342263 -3.09613986 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      "  3.58490343 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9996\n",
      "\n",
      "Example 27:\n",
      "Input Features: [-2.89097383 -2.77890005 -4.17293251 -1.08806787  0.88610978 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      "  3.58490343 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837  2.28464975 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786  4.03210436 -0.10766457\n",
      "  2.2401525  -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901  3.50212972\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145  4.59784336 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615   1.29838111 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      "  1.75116414 -0.10726318  2.48149709 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909  2.93268043  0.12166872 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106  2.20774682 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0001\n",
      "\n",
      "Example 28:\n",
      "Input Features: [ 0.42883612  1.31066672 -0.0111203   0.73342263  0.11220989 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818  6.85681944 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9309\n",
      "\n",
      "Example 29:\n",
      "Input Features: [ 0.93850949  0.87898347 -0.35405944 -0.17732262  1.11025321  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      "  3.58490343 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944  6.38457432 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9976\n",
      "\n",
      "Example 30:\n",
      "Input Features: [ 0.25937672 -1.65802611 -0.0111203   0.73342263 -1.9720005  -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928  3.46905571  0.9481445   1.99902993 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498  2.49277049\n",
      "  2.18676342 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.1173\n",
      "\n",
      "Example 31:\n",
      "Input Features: [ 0.66026944 -0.09751043  0.69337499  0.73342263 -3.09613986 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9989\n",
      "\n",
      "Example 32:\n",
      "Input Features: [-0.08018966 -0.72828046 -0.0111203   0.73342263 -1.67763392 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928  3.46905571  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837  3.91267623 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703  4.39869507 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457  5.83506815 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269  7.20130261 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9707\n",
      "\n",
      "Example 33:\n",
      "Input Features: [-0.63461696 -0.3873404   0.69337499 -0.63269525 -0.74005249 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294 -1.44128935 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058   4.73742962 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9905\n",
      "\n",
      "Example 34:\n",
      "Input Features: [-0.08018966 -2.77890005  0.35138481 -1.08806787  0.15575841 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855  0.62836739 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786  5.86779921 -0.10766457\n",
      "  2.2401525  -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828  5.50078317 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344  4.37218446 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588  9.49042214 -0.26902293\n",
      " -0.04534427  2.7392943  -0.3268058   0.94098558 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      "  4.79072751 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0005\n",
      "\n",
      "Example 35:\n",
      "Input Features: [-1.33378427  1.31066672 -0.0111203   0.73342263  0.54181936  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      "  3.58490343 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818  0.75912035 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162  0.11031152 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.6117\n",
      "\n",
      "Example 36:\n",
      "Input Features: [ 0.42915992  0.36263454 -0.0111203   0.73342263 -1.26274753  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435    4.90892823 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9615\n",
      "\n",
      "Example 37:\n",
      "Input Features: [ 0.31879301 -2.77890005 -0.92872751  0.73342263 -0.74005249 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532 -1.44128935 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909  1.66574264 -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0006\n",
      "\n",
      "Example 38:\n",
      "Input Features: [-2.46993116 -0.26411911 -0.14550341 -1.99881312 -1.67763392  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532 -1.44128935 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.5241\n",
      "\n",
      "Example 39:\n",
      "Input Features: [ 0.93850949 -0.19262684 -0.0111203   0.73342263 -0.08328465 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928  3.46905571  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435    4.90892823 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      "  5.17824162 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9901\n",
      "\n",
      "Example 40:\n",
      "Input Features: [ 0.6838347  -2.77890005 -4.17293251 -1.99881312 -0.08328465 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294 -0.04697996 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      "  2.2401525  -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      "  5.08041545 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      "  0.96891298 -0.10726318  1.44286546 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427  1.99603485  0.33926184  4.23556012 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106  1.29332222 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0003\n",
      "\n",
      "Example 41:\n",
      "Input Features: [ 0.42915992 -1.33069766 -4.17293251 -1.5434405  -0.55349456  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294 -1.44128935 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0018\n",
      "\n",
      "Example 42:\n",
      "Input Features: [-1.00917088  0.44890197 -0.14550341 -1.08806787 -0.74005249  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294 -1.44128935 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445   1.99902993 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265  4.01388711 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548  2.86403201 -0.06160474 -0.16164    -0.11714498  2.49277049\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145  3.05963544 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615   1.82777362 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058   0.72339095 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.4824\n",
      "\n",
      "Example 43:\n",
      "Input Features: [ 0.00893477  0.11750473 -0.0111203  -1.99881312 -0.55349456 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      "  8.03112983 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498  3.4362055  -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615   2.46011181 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909  0.62924488 -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9018\n",
      "\n",
      "Example 44:\n",
      "Input Features: [ 0.33833799  1.19574919 -0.0111203   0.73342263 -2.38688689 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      "  1.52825211 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9345\n",
      "\n",
      "Example 45:\n",
      "Input Features: [ 0.2107439   1.31066672  0.20674424  0.73342263 -3.09613986 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294 -1.44128935 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567  0.89622474 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402  1.60421692 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669  2.31450961\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      "  4.73566463 -0.15536574 11.54298102 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9120\n",
      "\n",
      "Example 46:\n",
      "Input Features: [-1.42540902e+00 -2.01378456e+00 -4.17293251e+00  7.33422628e-01\n",
      " -3.95762073e-01 -9.17359188e-01 -1.64760418e-01 -2.22697745e-02\n",
      " -1.67466192e-01  1.22499294e+00  6.50174738e-01 -1.25855172e-01\n",
      " -2.71739278e-01 -2.88262883e-01 -1.05469156e+00 -5.00242636e-01\n",
      " -8.34950952e-02 -3.25396796e-01 -5.41587643e-01 -1.75948368e-01\n",
      " -1.93288546e-01 -1.89125674e-01 -1.53190246e-01  5.83012762e-01\n",
      " -8.70721080e-02 -1.24631740e-01 -4.91226529e-02 -2.41297856e-01\n",
      " -2.39196944e-01 -1.07664568e-01  2.24015250e+00 -1.16312625e-01\n",
      " -2.50435628e-01 -1.08984017e-01 -1.15969555e-01  1.90289470e+00\n",
      " -8.10616197e-02 -1.97895707e-01 -1.24957535e-01 -4.52116592e-02\n",
      " -1.48376695e-01 -9.80068262e-02 -1.24515482e-01 -3.42919378e-01\n",
      " -6.16047393e-02 -1.61640004e-01 -1.17144979e-01 -3.95346591e-01\n",
      " -1.48667026e-01 -1.74710873e-01 -7.52347516e-02 -1.29875868e-01\n",
      " -1.55419013e-01 -1.13649505e-01  1.30665463e-02 -3.34284982e-01\n",
      " -2.91018683e-01 -7.99468099e-02 -6.91252129e-02 -1.35070319e-01\n",
      " -1.33157883e-01 -1.27238276e-01 -1.36899357e-01 -1.20391452e-01\n",
      " -1.08112860e-01 -5.47634295e-02 -1.61552178e-01 -2.16740297e-01\n",
      " -2.50905845e-01 -2.20503762e-01 -5.06071757e-02 -6.63313936e-02\n",
      " -3.83614985e-02 -2.30453648e-01  2.03115690e+01 -1.17435001e-01\n",
      " -1.94492694e-01 -1.27095264e-01 -1.23123439e-01 -1.58196677e-01\n",
      " -2.04817658e-01 -1.20316971e-01 -5.06565849e-01 -4.16672467e-02\n",
      " -2.70377639e-01 -1.07263182e-01 -2.02598945e-01 -6.41358754e-02\n",
      " -1.08354167e-01 -2.69022925e-01 -4.53442669e-02 -2.92399086e-01\n",
      "  7.09046699e-01  6.56909041e-01 -5.22429414e-02 -1.69215441e-01\n",
      " -9.21659987e-02 -1.21239444e-01 -1.78704574e-01 -1.60674018e-01\n",
      " -7.09836149e-02 -1.70329645e-01 -2.18631058e-01 -1.55365735e-01\n",
      " -1.23572686e-01 -1.65997670e-01 -8.53966115e-02 -4.79526982e-02]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0003\n",
      "\n",
      "Example 47:\n",
      "Input Features: [-3.05564663 -0.48355357  0.69337499  0.73342263  0.51215827 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      "  2.2401525  -0.11631263 -0.25043563 -0.10898402 -0.11596955  1.9028947\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9975\n",
      "\n",
      "Example 48:\n",
      "Input Features: [ 0.13268007 -2.77890005  0.22371146 -1.99881312 -0.96838095 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619 -0.81045532 -1.44128935 -0.12585517\n",
      " -0.27173928  3.46905571  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025 -1.71954262\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      "  7.50988207 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427 -0.29239909  0.50560868 -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0051\n",
      "\n",
      "Example 49:\n",
      "Input Features: [-1.49609097 -0.45822575  0.69337499  0.73342263 -0.03079952 -0.91735919\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288 -1.05469156 -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855 -0.18912567 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828  4.97962258 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697  1.95332384 -0.04166725\n",
      " -0.27037764 -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427  3.89360276 -0.3268058  -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 1\n",
      "Predicted Label: 1\n",
      "Predicted Probability (Positive Class): 0.9872\n",
      "\n",
      "Example 50:\n",
      "Input Features: [-0.08018966 -2.77890005  0.56113837 -0.17732262  1.33522129  1.09008556\n",
      " -0.16476042 -0.02226977 -0.16746619  1.22499294  0.65017474 -0.12585517\n",
      " -0.27173928 -0.28826288  0.9481445  -0.50024264 -0.0834951  -0.3253968\n",
      " -0.54158764 -0.17594837 -0.19328855  8.02616072 -0.15319025  0.58301276\n",
      " -0.08707211 -0.12463174 -0.04912265 -0.24129786 -0.23919694 -0.10766457\n",
      " -0.44639818 -0.11631263 -0.25043563 -0.10898402 -0.11596955 -0.52551515\n",
      " -0.08106162 -0.19789571 -0.12495753 -0.04521166 -0.14837669 -0.09800683\n",
      " -0.12451548 -0.34291938 -0.06160474 -0.16164    -0.11714498 -0.39534659\n",
      " -0.14866703 -0.17471087 -0.07523475 -0.12987587 -0.15541901 -0.1136495\n",
      "  0.01306655 -0.33428498 -0.29101868 -0.07994681 -0.06912521 -0.13507032\n",
      " -0.13315788 -0.12723828 -0.13689936 -0.12039145 -0.10811286 -0.05476343\n",
      " -0.16155218 -0.2167403  -0.25090584 -0.22050376 -0.05060718 -0.06633139\n",
      " -0.0383615  -0.23045365 -0.04474702 -0.117435   -0.19449269 -0.12709526\n",
      " -0.12312344 -0.15819668 -0.20481766 -0.12031697 -0.50656585 -0.04166725\n",
      "  3.9227119  -0.10726318 -0.20259895 -0.06413588 -0.10835417 -0.26902293\n",
      " -0.04534427  0.93876738  1.92680705 -0.46859772 -0.05224294 -0.16921544\n",
      " -0.092166   -0.12123944 -0.17870457 -0.16067402 -0.07098361 -0.17032964\n",
      " -0.21863106 -0.15536574 -0.12357269 -0.16599767 -0.08539661 -0.0479527 ]\n",
      "Actual Label: 0\n",
      "Predicted Label: 0\n",
      "Predicted Probability (Positive Class): 0.0011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test_reduced)[:, 1] \n",
    "y_pred_test = xgb_model.predict(X_test_reduced) \n",
    "\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))  \n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test:.4f}\")\n",
    "\n",
    "print(\"\\n📝 Sample Inputs and Predictions:\")\n",
    "num_samples = 50\n",
    "for i in range(num_samples):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Input Features: {X_test_reduced.iloc[i].values}\")\n",
    "    \n",
    "    print(f\"Actual Label: {y_test.iloc[i]}\")\n",
    "    \n",
    "    print(f\"Predicted Label: {y_pred_test[i]}\")\n",
    "    \n",
    "    print(f\"Predicted Probability (Positive Class): {y_pred_proba_test[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Top 20 Features by Importance:\n",
      "                                    Feature  Importance\n",
      "                              Interventions    0.079429\n",
      "                                 Enrollment    0.057274\n",
      "         reason_study_terminated_by_sponsor    0.029829\n",
      "                                 Conditions    0.020659\n",
      " Study_Design_Intervention_Model__CROSSOVER    0.017342\n",
      "                      reason_90_100_percent    0.017246\n",
      "                       reason_80_90_percent    0.016938\n",
      "                             country_Turkey    0.015204\n",
      "                       period_81_90_percent    0.012739\n",
      "  Study_Design_Intervention_Model__PARALLEL    0.009847\n",
      "                             country_France    0.009683\n",
      "Study_Design_Intervention_Model__SEQUENTIAL    0.009540\n",
      "                      country_United_States    0.008141\n",
      "                         healthy_volunteers    0.008096\n",
      "                      reason_administrative    0.008030\n",
      "                             country_Canada    0.007449\n",
      "        TFIDF_secondaryoutcomes_symptomatic    0.007253\n",
      "                      period_91_100_percent    0.007196\n",
      "               Study_Design_Masking__DOUBLE    0.006894\n",
      "                             country_Israel    0.006836\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train_reduced.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "top_features = feature_importance_df.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['Feature'], top_features['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 20 Features by Importance (XGBoost)')\n",
    "plt.gca().invert_yaxis()  \n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 Top 20 Features by Importance:\")\n",
    "print(top_features.to_string(index=False))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Top 10 Features by Importance:\n",
      "['Interventions', 'Enrollment', 'reason_study_terminated_by_sponsor', 'Conditions', 'Study_Design_Intervention_Model__CROSSOVER', 'reason_90_100_percent', 'reason_80_90_percent', 'country_Turkey', 'period_81_90_percent', 'Study_Design_Intervention_Model__PARALLEL']\n",
      "\n",
      "🎯 XGBoost Model Performance on Top 10 Features (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72      7267\n",
      "           1       0.97      0.93      0.95     44248\n",
      "\n",
      "    accuracy                           0.91     51515\n",
      "   macro avg       0.81      0.87      0.83     51515\n",
      "weighted avg       0.92      0.91      0.92     51515\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9485\n",
      "\n",
      "🎯 XGBoost Model Performance on Top 10 Features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72      7267\n",
      "           1       0.97      0.93      0.95     44249\n",
      "\n",
      "    accuracy                           0.91     51516\n",
      "   macro avg       0.81      0.87      0.83     51516\n",
      "weighted avg       0.92      0.91      0.92     51516\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9487\n"
     ]
    }
   ],
   "source": [
    "# Get the top 10 features based on importance\n",
    "top_10_features = feature_importance_df.head(10)['Feature'].tolist()\n",
    "\n",
    "# Print the top 10 features\n",
    "print(\"\\n📊 Top 10 Features by Importance:\")\n",
    "print(top_10_features)\n",
    "\n",
    "# Select only the top 10 features from the training, validation, and test sets\n",
    "X_train_top10 = X_train_reduced[top_10_features]\n",
    "X_val_top10 = X_val_reduced[top_10_features]\n",
    "X_test_top10 = X_test_reduced[top_10_features]\n",
    "\n",
    "# Train the XGBoost model on the top 10 features\n",
    "xgb_model_top10 = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "xgb_model_top10.fit(X_train_top10, y_train)\n",
    "\n",
    "# Predict on validation and test sets with the new model\n",
    "y_pred_val_top10 = xgb_model_top10.predict(X_val_top10)\n",
    "y_pred_test_top10 = xgb_model_top10.predict(X_test_top10)\n",
    "\n",
    "# Evaluate model performance on validation set\n",
    "y_pred_proba_val_top10 = xgb_model_top10.predict_proba(X_val_top10)[:, 1]\n",
    "roc_auc_val_top10 = roc_auc_score(y_val, y_pred_proba_val_top10)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance on Top 10 Features (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val_top10))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val_top10:.4f}\")\n",
    "\n",
    "# Evaluate model performance on test set\n",
    "y_pred_proba_test_top10 = xgb_model_top10.predict_proba(X_test_top10)[:, 1]\n",
    "roc_auc_test_top10 = roc_auc_score(y_test, y_pred_proba_test_top10)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance on Top 10 Features (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test_top10))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test_top10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Top 5 Features by Importance:\n",
      "['Interventions', 'Enrollment', 'reason_study_terminated_by_sponsor', 'Conditions', 'Study_Design_Intervention_Model__CROSSOVER']\n",
      "\n",
      "🎯 XGBoost Model Performance on Top 5 Features (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.71      7267\n",
      "           1       0.97      0.92      0.94     44248\n",
      "\n",
      "    accuracy                           0.91     51515\n",
      "   macro avg       0.80      0.86      0.83     51515\n",
      "weighted avg       0.92      0.91      0.91     51515\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9445\n",
      "\n",
      "🎯 XGBoost Model Performance on Top 5 Features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.80      0.71      7267\n",
      "           1       0.97      0.92      0.94     44249\n",
      "\n",
      "    accuracy                           0.91     51516\n",
      "   macro avg       0.80      0.86      0.83     51516\n",
      "weighted avg       0.92      0.91      0.91     51516\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9451\n"
     ]
    }
   ],
   "source": [
    "# Get the top 5 features based on importance\n",
    "top_5_features = feature_importance_df.head(5)['Feature'].tolist()\n",
    "\n",
    "# Print the top 5 features\n",
    "print(\"\\n📊 Top 5 Features by Importance:\")\n",
    "print(top_5_features)\n",
    "\n",
    "# Select only the top 5 features from the training, validation, and test sets\n",
    "X_train_top5 = X_train_reduced[top_5_features]\n",
    "X_val_top5 = X_val_reduced[top_5_features]\n",
    "X_test_top5 = X_test_reduced[top_5_features]\n",
    "\n",
    "# Train the XGBoost model on the top 5 features\n",
    "xgb_model_top5 = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "xgb_model_top5.fit(X_train_top5, y_train)\n",
    "\n",
    "# Predict on validation and test sets with the new model\n",
    "y_pred_val_top5 = xgb_model_top5.predict(X_val_top5)\n",
    "y_pred_test_top5 = xgb_model_top5.predict(X_test_top5)\n",
    "\n",
    "# Evaluate model performance on validation set\n",
    "y_pred_proba_val_top5 = xgb_model_top5.predict_proba(X_val_top5)[:, 1]\n",
    "roc_auc_val_top5 = roc_auc_score(y_val, y_pred_proba_val_top5)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance on Top 5 Features (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val_top5))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val_top5:.4f}\")\n",
    "\n",
    "# Evaluate model performance on test set\n",
    "y_pred_proba_test_top5 = xgb_model_top5.predict_proba(X_test_top5)[:, 1]\n",
    "roc_auc_test_top5 = roc_auc_score(y_test, y_pred_proba_test_top5)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance on Top 5 Features (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test_top5))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test_top5:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming `X_train_top5.columns` contains the selected top 5 feature names\n",
    "selected_features = list(X_train_top5.columns)\n",
    "\n",
    "# Save the feature names used in training\n",
    "with open(\"training_features.pkl\", \"wb\") as f:\n",
    "    pickle.dump(selected_features, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Test data with top 5 features saved as 'X_test_top5_features.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Save the test data with the top 5 features to a CSV file\n",
    "X_test_top5.to_csv('X_test_top5_features.csv', index=False)\n",
    "\n",
    "print(\"✔ Test data with top 5 features saved as 'X_test_top5_features.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ XGBoost model on top 5 features saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to a pickle file\n",
    "with open('xgb_model_top5.pkl', 'wb') as f:\n",
    "    pickle.dump(xgb_model_top5, f)\n",
    "\n",
    "print(\"✔ XGBoost model on top 5 features saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing a new code for better 0 precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results with weight_ratio = 2.0:\n",
      "\n",
      "Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      7267\n",
      "           1       0.96      0.96      0.96     44248\n",
      "\n",
      "    accuracy                           0.93     51515\n",
      "   macro avg       0.87      0.86      0.86     51515\n",
      "weighted avg       0.93      0.93      0.93     51515\n",
      "\n",
      "\n",
      "Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      7267\n",
      "           1       0.96      0.96      0.96     44249\n",
      "\n",
      "    accuracy                           0.93     51516\n",
      "   macro avg       0.87      0.85      0.86     51516\n",
      "weighted avg       0.93      0.93      0.93     51516\n",
      "\n",
      "\n",
      "Optimal threshold: 0.5\n",
      "\n",
      "Final Results with Optimal Threshold:\n",
      "\n",
      "Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.25      0.07      7267\n",
      "           1       0.22      0.04      0.06     44248\n",
      "\n",
      "    accuracy                           0.07     51515\n",
      "   macro avg       0.13      0.14      0.07     51515\n",
      "weighted avg       0.20      0.07      0.06     51515\n",
      "\n",
      "\n",
      "Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.26      0.07      7267\n",
      "           1       0.23      0.04      0.06     44249\n",
      "\n",
      "    accuracy                           0.07     51516\n",
      "   macro avg       0.13      0.15      0.07     51516\n",
      "weighted avg       0.20      0.07      0.06     51516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# 1. Adjust class weights more aggressively\n",
    "def train_weighted_model(X_train, y_train, X_val, y_val, X_test, y_test, weight_ratio=2.0):\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,  # Slightly reduced to prevent overfitting\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        scale_pos_weight=weight_ratio * (y_train.value_counts()[0] / y_train.value_counts()[1]),\n",
    "        min_child_weight=3,  # Added to help with precision\n",
    "        gamma=1  # Added to make splits more conservative\n",
    "    )\n",
    "    \n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_val = xgb_model.predict(X_val)\n",
    "    y_pred_test = xgb_model.predict(X_test)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nResults with weight_ratio = {weight_ratio}:\")\n",
    "    print(\"\\nValidation Set:\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "    print(\"\\nTest Set:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    return xgb_model\n",
    "\n",
    "# 2. Probability threshold tuning\n",
    "def find_optimal_threshold(model, X_val, y_val, target_recall=0.80):\n",
    "    probabilities = model.predict_proba(X_val)[:, 1]\n",
    "    thresholds = np.arange(0.1, 0.9, 0.01)\n",
    "    best_threshold = 0.5\n",
    "    best_f1 = 0\n",
    "    best_precision = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        predictions = (probabilities < threshold).astype(int)  # Note: inverting threshold for class 0\n",
    "        \n",
    "        # Calculate metrics for class 0\n",
    "        true_pos = sum((predictions == 0) & (y_val == 0))\n",
    "        false_pos = sum((predictions == 0) & (y_val == 1))\n",
    "        false_neg = sum((predictions == 1) & (y_val == 0))\n",
    "        \n",
    "        recall = true_pos / (true_pos + false_neg)\n",
    "        if recall >= target_recall:  # Only consider thresholds that maintain target recall\n",
    "            precision = true_pos / (true_pos + false_pos) if (true_pos + false_pos) > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "            \n",
    "            if precision > best_precision:\n",
    "                best_precision = precision\n",
    "                best_threshold = threshold\n",
    "                best_f1 = f1\n",
    "    \n",
    "    return best_threshold\n",
    "\n",
    "# 3. Train and evaluate model with optimized parameters\n",
    "def train_optimized_model(X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # First train with adjusted weights\n",
    "    model = train_weighted_model(X_train, y_train, X_val, y_val, X_test, y_test, weight_ratio=2.0)\n",
    "    \n",
    "    # Find optimal threshold\n",
    "    optimal_threshold = find_optimal_threshold(model, X_val, y_val, target_recall=0.80)\n",
    "    print(f\"\\nOptimal threshold: {optimal_threshold}\")\n",
    "    \n",
    "    # Make predictions with optimal threshold\n",
    "    def predict_with_threshold(model, X, threshold):\n",
    "        probabilities = model.predict_proba(X)[:, 1]\n",
    "        return (probabilities < threshold).astype(int)\n",
    "    \n",
    "    # Final predictions\n",
    "    y_pred_val = predict_with_threshold(model, X_val, optimal_threshold)\n",
    "    y_pred_test = predict_with_threshold(model, X_test, optimal_threshold)\n",
    "    \n",
    "    print(\"\\nFinal Results with Optimal Threshold:\")\n",
    "    print(\"\\nValidation Set:\")\n",
    "    print(classification_report(y_val, y_pred_val))\n",
    "    print(\"\\nTest Set:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    return model, optimal_threshold\n",
    "\n",
    "# Use the functions\n",
    "model, threshold = train_optimized_model(X_train_top5, y_train, X_val_top5, y_val, X_test_top5, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Top 5 Features by Importance:\n",
      "['Interventions', 'Enrollment', 'reason_study_terminated_by_sponsor', 'Conditions', 'Study_Design_Intervention_Model__CROSSOVER']\n",
      "\n",
      "🎯 XGBoost Model Performance on Top 5 Features (Training Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79     21800\n",
      "           1       0.96      0.97      0.97    132745\n",
      "\n",
      "    accuracy                           0.94    154545\n",
      "   macro avg       0.88      0.87      0.88    154545\n",
      "weighted avg       0.94      0.94      0.94    154545\n",
      "\n",
      "🔹 AUC-ROC (Training Set): 0.9637\n",
      "\n",
      "🎯 XGBoost Model Performance on Top 5 Features (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.76      7267\n",
      "           1       0.96      0.96      0.96     44248\n",
      "\n",
      "    accuracy                           0.93     51515\n",
      "   macro avg       0.87      0.86      0.86     51515\n",
      "weighted avg       0.93      0.93      0.93     51515\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9464\n",
      "\n",
      "🎯 XGBoost Model Performance on Top 5 Features (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      7267\n",
      "           1       0.96      0.96      0.96     44249\n",
      "\n",
      "    accuracy                           0.93     51516\n",
      "   macro avg       0.87      0.85      0.86     51516\n",
      "weighted avg       0.93      0.93      0.93     51516\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9467\n",
      "\n",
      "📊 Feature Importance for Top 5 Features:\n",
      "                                      Feature  Importance\n",
      "1                                  Enrollment    0.329624\n",
      "0                               Interventions    0.316286\n",
      "2          reason_study_terminated_by_sponsor    0.146060\n",
      "4  Study_Design_Intervention_Model__CROSSOVER    0.109941\n",
      "3                                  Conditions    0.098089\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Get the top 5 features based on importance\n",
    "top_5_features_opt = feature_importance_df.head(5)['Feature'].tolist()\n",
    "\n",
    "# Print the top 5 features\n",
    "print(\"\\n📊 Top 5 Features by Importance:\")\n",
    "print(top_5_features_opt)\n",
    "\n",
    "# Select only the top 5 features from the training, validation, and test sets\n",
    "X_train_top5_opt = X_train_reduced[top_5_features_opt]\n",
    "X_val_top5_opt = X_val_reduced[top_5_features_opt]\n",
    "X_test_top5_opt = X_test_reduced[top_5_features_opt]\n",
    "\n",
    "# Train the XGBoost model on the top 5 features with optimized weight_ratio\n",
    "xgb_model_top5_opt = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=2.0 * (y_train.value_counts()[0] / y_train.value_counts()[1]),\n",
    "    min_child_weight=3,\n",
    "    gamma=1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "xgb_model_top5_opt.fit(X_train_top5_opt, y_train)\n",
    "\n",
    "# Predict on training, validation, and test sets\n",
    "y_pred_train_top5_opt = xgb_model_top5_opt.predict(X_train_top5_opt)\n",
    "y_pred_val_top5_opt = xgb_model_top5_opt.predict(X_val_top5_opt)\n",
    "y_pred_test_top5_opt = xgb_model_top5_opt.predict(X_test_top5_opt)\n",
    "\n",
    "# Get probability predictions for ROC-AUC calculation\n",
    "y_pred_proba_train_top5_opt = xgb_model_top5_opt.predict_proba(X_train_top5_opt)[:, 1]\n",
    "y_pred_proba_val_top5_opt = xgb_model_top5_opt.predict_proba(X_val_top5_opt)[:, 1]\n",
    "y_pred_proba_test_top5_opt = xgb_model_top5_opt.predict_proba(X_test_top5_opt)[:, 1]\n",
    "\n",
    "# Calculate ROC-AUC scores\n",
    "roc_auc_train_top5_opt = roc_auc_score(y_train, y_pred_proba_train_top5_opt)\n",
    "roc_auc_val_top5_opt = roc_auc_score(y_val, y_pred_proba_val_top5_opt)\n",
    "roc_auc_test_top5_opt = roc_auc_score(y_test, y_pred_proba_test_top5_opt)\n",
    "\n",
    "# Print model performance metrics\n",
    "print(\"\\n🎯 XGBoost Model Performance on Top 5 Features (Training Set):\")\n",
    "print(classification_report(y_train, y_pred_train_top5_opt))\n",
    "print(f\"🔹 AUC-ROC (Training Set): {roc_auc_train_top5_opt:.4f}\")\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance on Top 5 Features (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val_top5_opt))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val_top5_opt:.4f}\")\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance on Top 5 Features (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test_top5_opt))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test_top5_opt:.4f}\")\n",
    "\n",
    "# Calculate and display feature importance for the top 5 features\n",
    "feature_importance_opt = xgb_model_top5_opt.feature_importances_\n",
    "feature_importance_df_top5_opt = pd.DataFrame({\n",
    "    'Feature': top_5_features_opt,\n",
    "    'Importance': feature_importance_opt\n",
    "})\n",
    "feature_importance_df_top5_opt = feature_importance_df_top5_opt.sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\n📊 Feature Importance for Top 5 Features:\")\n",
    "print(feature_importance_df_top5_opt)\n",
    "\n",
    "# Save the model (optional)\n",
    "xgb_model_top5_opt.save_model('xgboost_top5_optimized_v2.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 01:43:52,159] A new study created in memory with name: no-name-651e3a32-dd96-4386-991a-0da590fb7602\n",
      "[I 2025-02-15 01:44:02,194] Trial 0 finished with value: -0.9689432063263839 and parameters: {'n_estimators': 141, 'max_depth': 11, 'learning_rate': 0.13678548889846046, 'subsample': 0.6430284143517218, 'colsample_bytree': 0.853200995004155, 'min_child_weight': 2, 'gamma': 4.295014206841673}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:44:33,411] Trial 1 finished with value: -0.9679052440538733 and parameters: {'n_estimators': 700, 'max_depth': 6, 'learning_rate': 0.11642810509382383, 'subsample': 0.962157900061356, 'colsample_bytree': 0.8445908134927397, 'min_child_weight': 6, 'gamma': 0.36311135800501493}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:45:23,749] Trial 2 finished with value: -0.9669543655524295 and parameters: {'n_estimators': 554, 'max_depth': 12, 'learning_rate': 0.06344153416833942, 'subsample': 0.670734490485893, 'colsample_bytree': 0.6080517801468437, 'min_child_weight': 7, 'gamma': 0.4022176484393031}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:45:46,055] Trial 3 finished with value: -0.9683898426665392 and parameters: {'n_estimators': 318, 'max_depth': 8, 'learning_rate': 0.10323645085193711, 'subsample': 0.8291505168561276, 'colsample_bytree': 0.7134515634207057, 'min_child_weight': 2, 'gamma': 2.658702860736094}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:46:15,021] Trial 4 finished with value: -0.9687604971447766 and parameters: {'n_estimators': 443, 'max_depth': 8, 'learning_rate': 0.20873666964122928, 'subsample': 0.7118369898077332, 'colsample_bytree': 0.6973649662170914, 'min_child_weight': 1, 'gamma': 2.820882752786136}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:46:24,065] Trial 5 finished with value: -0.9682562413480357 and parameters: {'n_estimators': 121, 'max_depth': 9, 'learning_rate': 0.1286649412534767, 'subsample': 0.9851215726433789, 'colsample_bytree': 0.9690623205294604, 'min_child_weight': 4, 'gamma': 1.4697021717587995}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:47:25,465] Trial 6 finished with value: -0.9683777448213176 and parameters: {'n_estimators': 644, 'max_depth': 11, 'learning_rate': 0.031775053927815794, 'subsample': 0.6097468570783905, 'colsample_bytree': 0.8427821207948025, 'min_child_weight': 1, 'gamma': 3.0329304195387365}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:48:24,247] Trial 7 finished with value: -0.9681522570772763 and parameters: {'n_estimators': 796, 'max_depth': 9, 'learning_rate': 0.1941064947265028, 'subsample': 0.9784664364808693, 'colsample_bytree': 0.6987966574784403, 'min_child_weight': 5, 'gamma': 2.977583742386622}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:49:23,122] Trial 8 finished with value: -0.9645352983123365 and parameters: {'n_estimators': 552, 'max_depth': 11, 'learning_rate': 0.1569546746032348, 'subsample': 0.6156123082413156, 'colsample_bytree': 0.7064304600451023, 'min_child_weight': 4, 'gamma': 0.08201817531949318}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:49:58,159] Trial 9 finished with value: -0.9656615618757729 and parameters: {'n_estimators': 526, 'max_depth': 9, 'learning_rate': 0.1955054127842796, 'subsample': 0.9116592121531333, 'colsample_bytree': 0.6416709195712236, 'min_child_weight': 3, 'gamma': 0.4887187082727118}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:52:44,754] Trial 10 finished with value: -0.9681265323782511 and parameters: {'n_estimators': 956, 'max_depth': 15, 'learning_rate': 0.29434879135734704, 'subsample': 0.7549045896038964, 'colsample_bytree': 0.9807559013613975, 'min_child_weight': 3, 'gamma': 4.889041402023626}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:52:49,855] Trial 11 finished with value: -0.9675603472951054 and parameters: {'n_estimators': 112, 'max_depth': 3, 'learning_rate': 0.24825890098578285, 'subsample': 0.7166199956191551, 'colsample_bytree': 0.78686788440014, 'min_child_weight': 1, 'gamma': 4.1144769345090175}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:53:14,090] Trial 12 finished with value: -0.9680795145027954 and parameters: {'n_estimators': 307, 'max_depth': 6, 'learning_rate': 0.20488185292462596, 'subsample': 0.8096441304631458, 'colsample_bytree': 0.7984751381739411, 'min_child_weight': 2, 'gamma': 3.8992574238800826}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:54:13,281] Trial 13 finished with value: -0.9644321540955468 and parameters: {'n_estimators': 339, 'max_depth': 14, 'learning_rate': 0.24368171787743031, 'subsample': 0.6911421973285705, 'colsample_bytree': 0.9053862266415277, 'min_child_weight': 1, 'gamma': 1.8079210226942748}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:54:45,494] Trial 14 finished with value: -0.9687080697718996 and parameters: {'n_estimators': 415, 'max_depth': 6, 'learning_rate': 0.16575362021137477, 'subsample': 0.7531600887021448, 'colsample_bytree': 0.7471470396480536, 'min_child_weight': 2, 'gamma': 3.7855641457538045}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:55:16,356] Trial 15 finished with value: -0.9687350148652537 and parameters: {'n_estimators': 220, 'max_depth': 13, 'learning_rate': 0.08358692955465627, 'subsample': 0.6479858381483324, 'colsample_bytree': 0.9033542105880874, 'min_child_weight': 3, 'gamma': 4.830442715313282}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:55:47,237] Trial 16 finished with value: -0.9687364933006771 and parameters: {'n_estimators': 415, 'max_depth': 7, 'learning_rate': 0.23675300024432994, 'subsample': 0.7346989946206766, 'colsample_bytree': 0.6578578647572323, 'min_child_weight': 2, 'gamma': 1.951447929867511}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:55:56,691] Trial 17 finished with value: -0.9684911171766508 and parameters: {'n_estimators': 188, 'max_depth': 4, 'learning_rate': 0.2822153860252453, 'subsample': 0.8663797255119794, 'colsample_bytree': 0.8534389345895479, 'min_child_weight': 1, 'gamma': 3.42191026779871}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:57:38,935] Trial 18 finished with value: -0.9682661059070924 and parameters: {'n_estimators': 887, 'max_depth': 11, 'learning_rate': 0.01379586847019365, 'subsample': 0.6532247400877418, 'colsample_bytree': 0.7453303015031147, 'min_child_weight': 3, 'gamma': 4.362209987763194}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:58:29,693] Trial 19 finished with value: -0.9650499286733238 and parameters: {'n_estimators': 444, 'max_depth': 10, 'learning_rate': 0.14184977683471595, 'subsample': 0.7840191950529273, 'colsample_bytree': 0.928100731947905, 'min_child_weight': 2, 'gamma': 1.106967498712716}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:59:06,505] Trial 20 finished with value: -0.9679923334930522 and parameters: {'n_estimators': 256, 'max_depth': 13, 'learning_rate': 0.1698131474740812, 'subsample': 0.7052200237419008, 'colsample_bytree': 0.7587765790414847, 'min_child_weight': 5, 'gamma': 2.3934812485078627}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 01:59:36,670] Trial 21 finished with value: -0.9681141379805621 and parameters: {'n_estimators': 391, 'max_depth': 7, 'learning_rate': 0.22976727608214287, 'subsample': 0.7305218057984711, 'colsample_bytree': 0.6683587273749152, 'min_child_weight': 2, 'gamma': 1.9584161316751398}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:00:18,593] Trial 22 finished with value: -0.9684507851397932 and parameters: {'n_estimators': 487, 'max_depth': 7, 'learning_rate': 0.21624650701201553, 'subsample': 0.7674021766801497, 'colsample_bytree': 0.6404107189193989, 'min_child_weight': 1, 'gamma': 2.3109425311031657}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:01:16,570] Trial 23 finished with value: -0.9650369663725257 and parameters: {'n_estimators': 655, 'max_depth': 8, 'learning_rate': 0.2691477688907201, 'subsample': 0.6712806799771719, 'colsample_bytree': 0.6570151966934514, 'min_child_weight': 2, 'gamma': 1.1377469896374008}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:01:40,454] Trial 24 finished with value: -0.968814371257485 and parameters: {'n_estimators': 397, 'max_depth': 5, 'learning_rate': 0.25774065791917555, 'subsample': 0.7251930496030202, 'colsample_bytree': 0.6818359230546164, 'min_child_weight': 3, 'gamma': 3.3860558716985985}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:01:49,765] Trial 25 finished with value: -0.9685570710696338 and parameters: {'n_estimators': 180, 'max_depth': 4, 'learning_rate': 0.26284062069956965, 'subsample': 0.6325489224908342, 'colsample_bytree': 0.6053992267490209, 'min_child_weight': 3, 'gamma': 3.350218375868887}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:02:06,515] Trial 26 finished with value: -0.9683002629691609 and parameters: {'n_estimators': 275, 'max_depth': 5, 'learning_rate': 0.1797523393173785, 'subsample': 0.6916757218766416, 'colsample_bytree': 0.8818627175709558, 'min_child_weight': 4, 'gamma': 4.306177373679957}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:02:39,234] Trial 27 finished with value: -0.9680367481697689 and parameters: {'n_estimators': 353, 'max_depth': 10, 'learning_rate': 0.21198736258923276, 'subsample': 0.8148749293417749, 'colsample_bytree': 0.7743584937200592, 'min_child_weight': 5, 'gamma': 3.5449535107269883}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:03:09,219] Trial 28 finished with value: -0.9681696343097836 and parameters: {'n_estimators': 476, 'max_depth': 5, 'learning_rate': 0.14462772148327252, 'subsample': 0.6768571956785338, 'colsample_bytree': 0.7264657179868672, 'min_child_weight': 1, 'gamma': 2.8286783713798758}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:03:39,314] Trial 29 finished with value: -0.9683762319395273 and parameters: {'n_estimators': 598, 'max_depth': 3, 'learning_rate': 0.11368735671035161, 'subsample': 0.6003276614770294, 'colsample_bytree': 0.8236668453845164, 'min_child_weight': 4, 'gamma': 4.537166551095073}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:04:39,066] Trial 30 finished with value: -0.9684809642242204 and parameters: {'n_estimators': 746, 'max_depth': 8, 'learning_rate': 0.18185398414711432, 'subsample': 0.848984579468032, 'colsample_bytree': 0.6851828517844734, 'min_child_weight': 3, 'gamma': 3.1934416116989524}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:05:11,431] Trial 31 finished with value: -0.9680601446152373 and parameters: {'n_estimators': 391, 'max_depth': 7, 'learning_rate': 0.23466464856923014, 'subsample': 0.7354654419502293, 'colsample_bytree': 0.6797336058570627, 'min_child_weight': 2, 'gamma': 2.076297211164251}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:05:41,714] Trial 32 finished with value: -0.968419034839699 and parameters: {'n_estimators': 488, 'max_depth': 5, 'learning_rate': 0.25888243174653175, 'subsample': 0.78466899338246, 'colsample_bytree': 0.62899133589913, 'min_child_weight': 2, 'gamma': 3.7831666033456246}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:06:40,246] Trial 33 finished with value: -0.9679996173347364 and parameters: {'n_estimators': 580, 'max_depth': 8, 'learning_rate': 0.22673697967651332, 'subsample': 0.7251750970690487, 'colsample_bytree': 0.7277928447728602, 'min_child_weight': 1, 'gamma': 2.5763115670702867}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:07:22,325] Trial 34 finished with value: -0.9655634207002104 and parameters: {'n_estimators': 358, 'max_depth': 10, 'learning_rate': 0.27716298248610133, 'subsample': 0.6495999609944074, 'colsample_bytree': 0.6165304037053674, 'min_child_weight': 2, 'gamma': 1.6065074802461305}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[I 2025-02-15 02:07:45,836] Trial 35 finished with value: -0.968027145861212 and parameters: {'n_estimators': 273, 'max_depth': 7, 'learning_rate': 0.0849476650896122, 'subsample': 0.7077567230152395, 'colsample_bytree': 0.6546775026262558, 'min_child_weight': 3, 'gamma': 2.8001342719462072}. Best is trial 0 with value: -0.9689432063263839.\n",
      "[W 2025-02-15 02:08:20,679] Trial 36 failed with parameters: {'n_estimators': 450, 'max_depth': 12, 'learning_rate': 0.1329269294477331, 'subsample': 0.739437683614475, 'colsample_bytree': 0.6966091396029767, 'min_child_weight': 2, 'gamma': 2.316049906248308} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\yuvik\\AppData\\Local\\Temp\\ipykernel_29260\\3884151192.py\", line 25, in objective\n",
      "    model.fit(X_train_top5, y_train)\n",
      "  File \"c:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1400, in fit\n",
      "    self._Booster = train(\n",
      "  File \"c:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"c:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"c:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1778, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "[W 2025-02-15 02:08:20,694] Trial 36 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Create study\u001b[39;00m\n\u001b[0;32m     42\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Get best parameters\u001b[39;00m\n\u001b[0;32m     46\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\optuna\\study\\study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    385\u001b[0m \n\u001b[0;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    247\u001b[0m ):\n\u001b[1;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create and train model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m     22\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_top5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m     28\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_top5)\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1400\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1379\u001b[0m model, metric, params, early_stopping_rounds, callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(\n\u001b[0;32m   1380\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1381\u001b[0m )\n\u001b[0;32m   1382\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1383\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1384\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1397\u001b[0m     enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_categorical,\n\u001b[0;32m   1398\u001b[0m )\n\u001b[1;32m-> 1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yuvik\\anaconda3\\lib\\site-packages\\xgboost\\core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 7),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'scale_pos_weight': y_train.value_counts()[0] / y_train.value_counts()[1]  # Keep this fixed\n",
    "    }\n",
    "    \n",
    "    # Create and train model\n",
    "    model = xgb.XGBClassifier(\n",
    "        **params,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_top5, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_val_top5)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    current_recall = recall_score(y_val, y_pred)\n",
    "    baseline_recall = recall_score(y_val, y_pred_val_top5)  # Your original recall\n",
    "    \n",
    "    # Penalty if recall drops too much (more than 5% from baseline)\n",
    "    recall_penalty = max(0, (baseline_recall - current_recall - 0.05)) * 10\n",
    "    \n",
    "    # Objective: Maximize precision while maintaining recall\n",
    "    return -precision + recall_penalty  # Negative because Optuna minimizes\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = study.best_params\n",
    "print(\"\\n🔍 Best Parameters Found:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Train model with best parameters\n",
    "best_model = xgb.XGBClassifier(\n",
    "    **best_params,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "best_model.fit(X_train_top5, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_pred_val_tuned = best_model.predict(X_val_top5)\n",
    "y_pred_proba_val_tuned = best_model.predict_proba(X_val_top5)[:, 1]\n",
    "roc_auc_val_tuned = roc_auc_score(y_val, y_pred_proba_val_tuned)\n",
    "\n",
    "print(\"\\n🎯 Tuned XGBoost Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val_tuned))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val_tuned:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_test_tuned = best_model.predict(X_test_top5)\n",
    "y_pred_proba_test_tuned = best_model.predict_proba(X_test_top5)[:, 1]\n",
    "roc_auc_test_tuned = roc_auc_score(y_test, y_pred_proba_test_tuned)\n",
    "\n",
    "print(\"\\n🎯 Tuned XGBoost Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test_tuned))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test_tuned:.4f}\")\n",
    "\n",
    "# Compare with original model\n",
    "print(\"\\n📊 Performance Comparison:\")\n",
    "print(\"Original Model:\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred_val_top5):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred_val_top5):.4f}\")\n",
    "print(\"\\nTuned Model:\")\n",
    "print(f\"Precision: {precision_score(y_val, y_pred_val_tuned):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_val, y_pred_val_tuned):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 XGBoost Model Performance (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.71      3633\n",
      "           1       0.97      0.92      0.95     22125\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.80      0.87      0.83     25758\n",
      "weighted avg       0.92      0.91      0.91     25758\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9495\n",
      "\n",
      "🎯 XGBoost Model Performance (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.72      3634\n",
      "           1       0.97      0.93      0.95     22124\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.80      0.87      0.83     25758\n",
      "weighted avg       0.92      0.91      0.91     25758\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9498\n"
     ]
    }
   ],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_reduced.columns[:len(importances)],  # Match length of features\n",
    "    \"Importance\": importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "N = 10\n",
    "top_n_features = feature_importance_df[\"Feature\"].head(N).tolist()\n",
    "\n",
    "X_train_top_features = X_train_reduced[top_n_features]\n",
    "X_val_top_features = X_val_reduced[top_n_features]\n",
    "X_test_top_features = X_test_reduced[top_n_features]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight= y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "y_pred_val = xgb_model.predict(X_val_top_features)\n",
    "y_pred_test = xgb_model.predict(X_test_top_features)\n",
    "\n",
    "y_pred_proba_val = xgb_model.predict_proba(X_val_top_features)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val:.4f}\")\n",
    "\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test_top_features)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features Selected for Model:\n",
      "- Conditions\n",
      "- Enrollment\n",
      "- Interventions\n",
      "- Phases\n",
      "- duration\n",
      "- Study_Design_Intervention_Model__PARALLEL\n",
      "\n",
      "🎯 XGBoost Model Performance (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72      3633\n",
      "           1       0.97      0.93      0.95     22125\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.81      0.87      0.83     25758\n",
      "weighted avg       0.92      0.91      0.92     25758\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9507\n",
      "\n",
      "🎯 XGBoost Model Performance (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.80      0.72      3634\n",
      "           1       0.97      0.93      0.95     22124\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.81      0.87      0.84     25758\n",
      "weighted avg       0.92      0.91      0.92     25758\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9501\n"
     ]
    }
   ],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_reduced.columns[:len(importances)],  # Match length of features\n",
    "    \"Importance\": importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "N = 10\n",
    "top_n_features = feature_importance_df[\"Feature\"].head(N).tolist()\n",
    "\n",
    "# Print out the selected top features\n",
    "print(\"Top 10 Features Selected for Model:\")\n",
    "for feature in top_n_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "X_train_top_features = X_train_reduced[top_n_features]\n",
    "X_val_top_features = X_val_reduced[top_n_features]\n",
    "X_test_top_features = X_test_reduced[top_n_features]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight= y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "y_pred_val = xgb_model.predict(X_val_top_features)\n",
    "y_pred_test = xgb_model.predict(X_test_top_features)\n",
    "\n",
    "y_pred_proba_val = xgb_model.predict_proba(X_val_top_features)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val:.4f}\")\n",
    "\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test_top_features)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 Features Selected for Model:\n",
      "- Interventions\n",
      "- Enrollment\n",
      "- reason_study_terminated_by_sponsor\n",
      "- Conditions\n",
      "- Study_Design_Intervention_Model__CROSSOVER\n",
      "- reason_90_100_percent\n",
      "\n",
      "🎯 XGBoost Model Performance (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.81      0.71      3633\n",
      "           1       0.97      0.92      0.94     22125\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.80      0.87      0.83     25758\n",
      "weighted avg       0.92      0.91      0.91     25758\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9478\n",
      "\n",
      "🎯 XGBoost Model Performance (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.81      0.71      3634\n",
      "           1       0.97      0.92      0.95     22124\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.80      0.87      0.83     25758\n",
      "weighted avg       0.92      0.91      0.91     25758\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9478\n"
     ]
    }
   ],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_reduced.columns[:len(importances)],  # Match length of features\n",
    "    \"Importance\": importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "N = 6\n",
    "top_n_features = feature_importance_df[\"Feature\"].head(N).tolist()\n",
    "\n",
    "# Print out the selected top features\n",
    "print(\"Top 6 Features Selected for Model:\")\n",
    "for feature in top_n_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "X_train_top_features = X_train_reduced[top_n_features]\n",
    "X_val_top_features = X_val_reduced[top_n_features]\n",
    "X_test_top_features = X_test_reduced[top_n_features]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight= y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "y_pred_val = xgb_model.predict(X_val_top_features)\n",
    "y_pred_test = xgb_model.predict(X_test_top_features)\n",
    "\n",
    "y_pred_proba_val = xgb_model.predict_proba(X_val_top_features)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val:.4f}\")\n",
    "\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test_top_features)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 Features Selected for Model:\n",
      "- Conditions\n",
      "- Enrollment\n",
      "- Study_Design_Intervention_Model__PARALLEL\n",
      "- Interventions\n",
      "- Phases\n",
      "- duration\n",
      "\n",
      "🎯 XGBoost Model Performance (Validation Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.81      0.72      3633\n",
      "           1       0.97      0.93      0.95     22125\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.81      0.87      0.83     25758\n",
      "weighted avg       0.92      0.91      0.92     25758\n",
      "\n",
      "🔹 AUC-ROC (Validation Set): 0.9510\n",
      "\n",
      "🎯 XGBoost Model Performance (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.80      0.72      3634\n",
      "           1       0.97      0.93      0.95     22124\n",
      "\n",
      "    accuracy                           0.91     25758\n",
      "   macro avg       0.81      0.87      0.83     25758\n",
      "weighted avg       0.92      0.91      0.92     25758\n",
      "\n",
      "🔹 AUC-ROC (Test Set): 0.9495\n"
     ]
    }
   ],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_reduced.columns[:len(importances)],  # Match length of features\n",
    "    \"Importance\": importances\n",
    "})\n",
    "\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "N = 7\n",
    "top_n_features = feature_importance_df[\"Feature\"].head(N).tolist()\n",
    "\n",
    "# Print out the selected top features\n",
    "print(\"Top 7 Features Selected for Model:\")\n",
    "for feature in top_n_features:\n",
    "    print(f\"- {feature}\")\n",
    "\n",
    "X_train_top_features = X_train_reduced[top_n_features]\n",
    "X_val_top_features = X_val_reduced[top_n_features]\n",
    "X_test_top_features = X_test_reduced[top_n_features]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=10,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    scale_pos_weight= y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_top_features, y_train)\n",
    "\n",
    "y_pred_val = xgb_model.predict(X_val_top_features)\n",
    "y_pred_test = xgb_model.predict(X_test_top_features)\n",
    "\n",
    "y_pred_proba_val = xgb_model.predict_proba(X_val_top_features)[:, 1]\n",
    "roc_auc_val = roc_auc_score(y_val, y_pred_proba_val)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Validation Set):\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(f\"🔹 AUC-ROC (Validation Set): {roc_auc_val:.4f}\")\n",
    "\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test_top_features)[:, 1]\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test)\n",
    "\n",
    "print(\"\\n🎯 XGBoost Model Performance (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "print(f\"🔹 AUC-ROC (Test Set): {roc_auc_test:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
